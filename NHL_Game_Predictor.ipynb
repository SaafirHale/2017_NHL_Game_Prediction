{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = pd.read_csv(\"observations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's put the first 800 observations in our training data.\n",
    "training_df=observations[0:800]\n",
    "testing_df=observations[800:]\n",
    "\n",
    "# And now lets impute the missing data for each set independently\n",
    "training_df=training_df.fillna(training_df.mean())\n",
    "testing_df=testing_df.fillna(testing_df.mean())\n",
    "testing_df.head()\n",
    "\n",
    "features=training_df.drop('outcome_categorical', axis='columns')\n",
    "target=training_df['outcome_categorical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1188, 62)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 61)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the Target DataFrame into numerical categories. I.e. \"away\" to 0 and \"home\" to 1. This will comvert it to a NumPy Array.\n",
    "target = training_df['outcome_categorical'].factorize()[0]\n",
    "\n",
    "# Must convert it from a NumPy Array to a DataFrame\n",
    "target = pd.DataFrame(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training variables X_train and y_train.\n",
    "X_train = features\n",
    "y_train = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(random_state=1337),\n",
       "             param_grid={'max_depth': (3, 4, 5, 6, 7, 8, 9, 10),\n",
       "                         'min_samples_leaf': (1, 5, 10, 15, 20, 25)},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#%run m5p.py\n",
    "\n",
    "parameters={'max_depth':(3,4,5,6,7,8,9,10), \n",
    "            'min_samples_leaf':(1,5,10,15,20,25)}\n",
    "\n",
    "reg=GridSearchCV(estimator=DecisionTreeClassifier(random_state = 1337), param_grid=parameters, cv=10, scoring='r2')\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'min_samples_leaf': 20}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseSearchCV.score of GridSearchCV(cv=10, estimator=DecisionTreeClassifier(random_state=1337),\n",
       "             param_grid={'max_depth': (3, 4, 5, 6, 7, 8, 9, 10),\n",
       "                         'min_samples_leaf': (1, 5, 10, 15, 20, 25)},\n",
       "             scoring='r2')>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy Score: 0.5309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Now form a variable which has the correct labels and one which has the predictions\n",
    "labels=testing_df['outcome_categorical'].factorize()[0]\n",
    "predictions=reg.predict(testing_df.drop('outcome_categorical', axis='columns'))\n",
    "\n",
    "accurate = accuracy_score(labels,predictions)\n",
    "\n",
    "# And let's take a look at our results\n",
    "print(f\"Model Accuracy Score: {accuracy_score(labels,predictions):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
